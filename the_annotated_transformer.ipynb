{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b342fd3a",
   "metadata": {
    "id": "SX7UC-8jTsp7",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "\n",
    "<center><h1>The Annotated Transformer</h1> </center>\n",
    "\n",
    "\n",
    "<center>\n",
    "<p><a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need\n",
    "</a></p>\n",
    "</center>\n",
    "\n",
    "<img src=\"images/aiayn.png\" width=\"70%\"/>\n",
    "\n",
    "* *2022版本: Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak,\n",
    "   以及 Stella Biderman.*\n",
    "* *[原版](https://nlp.seas.harvard.edu/2018/04/03/attention.html):\n",
    "   [Sasha Rush](http://rush-nlp.com/).*\n",
    "\n",
    "\n",
    "在过去的五年里，Transformer一直是很多人关注的焦点。\n",
    "本文以逐行实现的形式呈现了论文的注解版本。相比原论文，本文重新组织并删除了\n",
    "一些章节，并在整篇文章中添加了注释。这份文档本身就是一个可运行的笔记本，\n",
    "应该是一个完全可用的实现。\n",
    "代码可在[此处](https://github.com/harvardnlp/annotated-transformer/)获取。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c950ce6",
   "metadata": {
    "id": "RSntDwKhTsp-",
    "lines_to_next_cell": 2
   },
   "source": [
    "<h3> 目录 </h3>\n",
    "<ul>\n",
    "<li><a href=\"#prelims\">准备工作</a></li>\n",
    "<li><a href=\"#background\">背景</a></li>\n",
    "<li><a href=\"#part-1-model-architecture\">第一部分：模型架构</a></li>\n",
    "<li><a href=\"#model-architecture\">模型架构</a><ul>\n",
    "<li><a href=\"#encoder-and-decoder-stacks\">编码器和解码器栈</a></li>\n",
    "<li><a href=\"#position-wise-feed-forward-networks\">位置前馈网络</a></li>\n",
    "<li><a href=\"#embeddings-and-softmax\">嵌入和Softmax</a></li>\n",
    "<li><a href=\"#positional-encoding\">位置编码</a></li>\n",
    "<li><a href=\"#full-model\">完整模型</a></li>\n",
    "<li><a href=\"#inference\">推理</a></li>\n",
    "</ul></li>\n",
    "<li><a href=\"#part-2-model-training\">第二部分：模型训练</a></li>\n",
    "<li><a href=\"#training\">训练</a><ul>\n",
    "<li><a href=\"#batches-and-masking\">批处理和掩码</a></li>\n",
    "<li><a href=\"#training-loop\">训练循环</a></li>\n",
    "<li><a href=\"#training-data-and-batching\">训练数据和批处理</a></li>\n",
    "<li><a href=\"#hardware-and-schedule\">硬件和调度</a></li>\n",
    "<li><a href=\"#optimizer\">优化器</a></li>\n",
    "<li><a href=\"#regularization\">正则化</a></li>\n",
    "</ul></li>\n",
    "<li><a href=\"#a-first-example\">第一个示例</a><ul>\n",
    "<li><a href=\"#synthetic-data\">合成数据</a></li>\n",
    "<li><a href=\"#loss-computation\">损失计算</a></li>\n",
    "<li><a href=\"#greedy-decoding\">贪婪解码</a></li>\n",
    "</ul></li>\n",
    "<li><a href=\"#part-3-a-real-world-example\">第三部分：真实世界示例</a>\n",
    "<ul>\n",
    "<li><a href=\"#data-loading\">数据加载</a></li>\n",
    "<li><a href=\"#iterators\">迭代器</a></li>\n",
    "<li><a href=\"#training-the-system\">系统训练</a></li>\n",
    "</ul></li>\n",
    "<li><a href=\"#additional-components-bpe-search-averaging\">附加组件：BPE、搜索、平均</a></li>\n",
    "<li><a href=\"#results\">结果</a><ul>\n",
    "<li><a href=\"#attention-visualization\">注意力可视化</a></li>\n",
    "<li><a href=\"#encoder-self-attention\">编码器自注意力</a></li>\n",
    "<li><a href=\"#decoder-self-attention\">解码器自注意力</a></li>\n",
    "<li><a href=\"#decoder-src-attention\">解码器源注意力</a></li>\n",
    "</ul></li>\n",
    "<li><a href=\"#conclusion\">结论</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e10fd",
   "metadata": {
    "id": "BhmOhn9lTsp8"
   },
   "source": [
    "# Prelims\n",
    "\n",
    "<a href=\"#background\">Skip</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc3278",
   "metadata": {
    "id": "NwClcbH6Tsp8"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b2840",
   "metadata": {
    "id": "NwClcbH6Tsp8",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # Uncomment for colab\n",
    "# #\n",
    "# !pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0d0d8",
   "metadata": {
    "id": "v1-1MX6oTsp9",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "# Set to False to skip notebook execution (e.g. for debugging)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43043862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some convenience helper functions used throughout the notebook\n",
    "\n",
    "\n",
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cec569",
   "metadata": {
    "id": "jx49WRyfTsp-"
   },
   "source": [
    "> 我的评论以引用块的形式呈现。正文内容均来自论文本身。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75bee1",
   "metadata": {
    "id": "7phVeWghTsp_"
   },
   "source": [
    "# 背景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640925ad",
   "metadata": {
    "id": "83ZDS91dTsqA"
   },
   "source": [
    "\n",
    "减少序列计算的目标也构成了扩展神经GPU、ByteNet和ConvS2S的基础,这些模型都使用卷积神经网络作为基本构建块,\n",
    "并行计算所有输入和输出位置的隐藏表示。在这些模型中,关联两个任意输入或输出位置的信号所需的操作数随着位置之间的\n",
    "距离而增长,ConvS2S呈线性增长,ByteNet呈对数增长。这使得学习远距离位置之间的依赖关系变得更加困难。在Transformer中,\n",
    "这被减少到恒定数量的操作,尽管代价是由于对注意力加权位置进行平均而导致有效分辨率降低,我们通过多头注意力机制来抵消这种影响。\n",
    "\n",
    "自注意力(有时称为内部注意力)是一种将单个序列的不同位置关联起来以计算序列表示的注意力机制。自注意力已经在多种任务中\n",
    "成功应用,包括阅读理解、抽象摘要、文本蕴含和学习与任务无关的句子表示。端到端记忆网络基于循环注意力机制而不是序列对齐的\n",
    "循环机制,已被证明在简单语言问答和语言建模任务上表现良好。\n",
    "\n",
    "然而,据我们所知,Transformer是第一个完全依赖自注意力来计算其输入和输出表示的转导模型,不使用序列对齐的RNN或卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ed7cf",
   "metadata": {},
   "source": [
    "# 第一部分：模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbf1c4",
   "metadata": {
    "id": "pFrPajezTsqB"
   },
   "source": [
    "# 模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0a04",
   "metadata": {
    "id": "ReuU_h-fTsqB"
   },
   "source": [
    "\n",
    "大多数具有竞争力的神经序列转导模型都具有编码器-解码器结构\n",
    "[(引用)](https://arxiv.org/abs/1409.0473)。在这里,编码器将符号表示的输入序列$(x_1, ..., x_n)$映射到\n",
    "连续表示序列$\\mathbf{z} = (z_1, ..., z_n)$。给定$\\mathbf{z}$,解码器然后一次生成一个符号,\n",
    "生成输出序列$(y_1,...,y_m)$。在每一步,模型都是自回归的\n",
    "[(引用)](https://arxiv.org/abs/1308.0850),在生成下一个符号时将先前生成的符号作为额外输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a35d9",
   "metadata": {
    "id": "k0XGXhzRTsqB"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92e3af",
   "metadata": {
    "id": "NKGoH2RsTsqC",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5381a1a",
   "metadata": {
    "id": "mOoEnF_jTsqC"
   },
   "source": [
    "\n",
    "Transformer遵循这种整体架构，对编码器和解码器都使用堆叠的自注意力层和逐点全连接层，\n",
    "分别如图1的左半部分和右半部分所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e389d9f",
   "metadata": {
    "id": "oredWloYTsqC",
    "lines_to_next_cell": 2
   },
   "source": [
    "![](images/ModalNet-21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff6459",
   "metadata": {
    "id": "bh092NZBTsqD"
   },
   "source": [
    "## 编码器和解码器堆叠\n",
    "\n",
    "### 编码器\n",
    "\n",
    "编码器由$N=6$个相同的层堆叠而成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74351f",
   "metadata": {
    "id": "2gxTApUYTsqD"
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658479e",
   "metadata": {
    "id": "xqVTz9MkTsqD"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435f78e",
   "metadata": {
    "id": "GjAKgjGwTsqD"
   },
   "source": [
    "\n",
    "我们在两个子层的周围都使用了残差连接\n",
    "[(引用)](https://arxiv.org/abs/1512.03385)，并在其后进行层归一化\n",
    "[(引用)](https://arxiv.org/abs/1607.06450)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1f64b",
   "metadata": {
    "id": "3jKa_prZTsqE"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa32d2f",
   "metadata": {
    "id": "nXSJ3QYmTsqE"
   },
   "source": [
    "\n",
    "也就是说，每个子层的输出是 $\\mathrm{LayerNorm}(x + \\mathrm{Sublayer}(x))$，\n",
    "其中 $\\mathrm{Sublayer}(x)$ 是由子层本身实现的函数。我们在每个子层的输出上\n",
    "应用 dropout [(引用)](http://jmlr.org/papers/v15/srivastava14a.html)，\n",
    "然后将其与子层的输入相加并进行归一化。\n",
    "\n",
    "为了便于实现这些残差连接，模型中的所有子层以及嵌入层都产生维度为\n",
    "$d_{\\text{model}}=512$ 的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e55024",
   "metadata": {
    "id": "U1P7zI0eTsqE"
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f31a22",
   "metadata": {
    "id": "ML6oDlEqTsqE"
   },
   "source": [
    "\n",
    "每一层都包含两个子层。第一个是多头自注意力机制，第二个是简单的基于位置的\n",
    "全连接前馈网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05ea3f",
   "metadata": {
    "id": "qYkUFr6GTsqE"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c801e3",
   "metadata": {
    "id": "7ecOQIhkTsqF"
   },
   "source": [
    "### Decoder\n",
    "\n",
    "The decoder is also composed of a stack of $N=6$ identical layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbbdd0",
   "metadata": {
    "id": "dXlCB12pTsqF"
   },
   "source": [
    "\n",
    "除了每个编码器层中的两个子层外，解码器还插入了第三个子层，该子层对编码器栈的输出执行多头注意力计算。\n",
    "与编码器类似，我们在每个子层周围使用残差连接，然后进行层归一化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f6eb9",
   "metadata": {
    "id": "M2hA1xFQTsqF"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada36245",
   "metadata": {
    "id": "FZz5rLl4TsqF"
   },
   "source": [
    "\n",
    "我们还修改了解码器栈中的自注意力子层，以防止位置关注后续位置。这种掩码机制，\n",
    "结合输出嵌入偏移一个位置的事实，确保了位置 $i$ 的预测只能依赖于位置小于 $i$ 的已知输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f5ffc",
   "metadata": {
    "id": "QN98O2l3TsqF"
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f07008",
   "metadata": {
    "id": "Vg_f_w-PTsqG"
   },
   "source": [
    "\n",
    "> 下面的注意力掩码展示了每个目标词（行）被允许关注的位置（列）。\n",
    "> 在训练过程中，词语被阻止关注未来的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cdd7c",
   "metadata": {
    "id": "ht_FtgYAokC4"
   },
   "outputs": [],
   "source": [
    "def example_mask():\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
    "                    \"Window\": y,\n",
    "                    \"Masking\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(20)\n",
    "            for x in range(20)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()\n",
    "        .properties(height=250, width=250)\n",
    "        .encode(\n",
    "            alt.X(\"Window:O\"),\n",
    "            alt.Y(\"Masking:O\"),\n",
    "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94027de7",
   "metadata": {
    "id": "Qto_yg7BTsqG",
    "lines_to_next_cell": 2
   },
   "source": [
    "### 注意力机制\n",
    "\n",
    "注意力函数可以描述为将一个查询(query)和一组键值对(key-value pairs)映射到一个输出的过程，\n",
    "其中查询、键、值和输出都是向量。输出是值的加权和，其中分配给每个值的权重是通过查询和相应键之间的\n",
    "相容性函数计算得到的。\n",
    "\n",
    "我们将我们特定的注意力机制称为\"缩放点积注意力\"(Scaled Dot-Product Attention)。\n",
    "输入包含维度为$d_k$的查询和键，以及维度为$d_v$的值。我们计算查询和所有键的点积，\n",
    "将每个点积除以$\\sqrt{d_k}$，然后应用softmax函数来获得值的权重。\n",
    "\n",
    "![](images/ModalNet-19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9fd11a",
   "metadata": {
    "id": "EYJLWk6cTsqG"
   },
   "source": [
    "\n",
    "在实践中，我们同时对一组查询计算注意力函数，将它们打包到一个矩阵$Q$中。键和值也被打包到\n",
    "矩阵$K$和$V$中。我们按如下方式计算输出矩阵：\n",
    "\n",
    "$$\n",
    "   \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855e2b0",
   "metadata": {
    "id": "qsoVxS5yTsqG",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191917cc",
   "metadata": {
    "id": "jUkpwu8kTsqG"
   },
   "source": [
    "\n",
    "两种最常用的注意力函数是加性注意力[(引用)](https://arxiv.org/abs/1409.0473)和点积\n",
    "(乘性)注意力。点积注意力与我们的算法相同，只是多了一个缩放因子$\\frac{1}{\\sqrt{d_k}}$。\n",
    "加性注意力使用一个具有单个隐藏层的前馈网络来计算相容性函数。虽然这两种方法在理论复杂度上\n",
    "相似，但点积注意力在实践中更快且空间效率更高，因为它可以使用高度优化的矩阵乘法代码来实现。\n",
    "\n",
    "\n",
    "虽然对于较小的$d_k$值，这两种机制表现相似，但在没有缩放的情况下，当$d_k$值较大时，\n",
    "加性注意力的性能优于点积注意力[(引用)](https://arxiv.org/abs/1703.03906)。我们推测，\n",
    "对于较大的$d_k$值，点积的幅度会变得很大，将softmax函数推入梯度极小的区域(为说明点积\n",
    "为什么会变大，假设$q$和$k$的分量是均值为$0$、方差为$1$的独立随机变量。那么它们的点积\n",
    "$q \\cdot k = \\sum_{i=1}^{d_k} q_ik_i$的均值为$0$，方差为$d_k$)。为了抵消这种效果，\n",
    "我们用$\\frac{1}{\\sqrt{d_k}}$对点积进行缩放。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50529db0",
   "metadata": {
    "id": "bS1FszhVTsqG",
    "lines_to_next_cell": 2
   },
   "source": [
    "![](images/ModalNet-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4a571",
   "metadata": {
    "id": "TNtVyZ-pTsqH"
   },
   "source": [
    "\n",
    "多头注意力使模型能够在不同位置同时关注来自不同表示子空间的信息。使用单个注意力头会\n",
    "因为平均化而抑制这种能力。\n",
    "\n",
    "$$\n",
    "\\mathrm{MultiHead}(Q, K, V) =\n",
    "    \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O \\\\\n",
    "    \\text{其中}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
    "$$\n",
    "\n",
    "其中投影是参数矩阵$W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$、\n",
    "$W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$、\n",
    "$W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$和\n",
    "$W^O \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$。\n",
    "\n",
    "在本工作中，我们使用了$h=8$个并行的注意力层，即头。对于每个头，我们使用\n",
    "$d_k=d_v=d_{\\text{model}}/h=64$。由于每个头的维度减小，总的计算成本与使用\n",
    "完整维度的单头注意力相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a230f",
   "metadata": {
    "id": "D2LBMKCQTsqH"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559cc7d",
   "metadata": {
    "id": "EDRba3J3TsqH"
   },
   "source": [
    "### 我们模型中注意力机制的应用\n",
    "\n",
    "Transformer以三种不同的方式使用多头注意力:\n",
    "1) 在\"编码器-解码器注意力\"层中,查询来自前一个解码器层,而记忆键和值来自编码器的输出。\n",
    "这使得解码器的每个位置都能关注输入序列的所有位置。这模仿了序列到序列模型中典型的编码器-解码器\n",
    "注意力机制,如[(引用)](https://arxiv.org/abs/1609.08144)。\n",
    "\n",
    "2) 编码器包含自注意力层。在自注意力层中,所有的键、值和查询都来自同一个地方,在这种情况下,\n",
    "是编码器中前一层的输出。编码器中的每个位置都可以关注编码器前一层的所有位置。\n",
    "\n",
    "3) 类似地,解码器中的自注意力层允许解码器的每个位置关注解码器中直到该位置(包括该位置)的所有位置。\n",
    "我们需要防止解码器中的信息向左流动以保持自回归特性。我们通过在缩放点积注意力中将softmax输入中\n",
    "对应于非法连接的所有值屏蔽(设置为$-\\infty$)来实现这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0b49f",
   "metadata": {
    "id": "M-en97_GTsqH"
   },
   "source": [
    "## 位置前馈网络\n",
    "\n",
    "除了注意力子层外,我们的编码器和解码器中的每一层都包含一个全连接前馈网络,\n",
    "该网络分别且相同地应用于每个位置。这包括两个线性变换,中间有一个ReLU激活函数。\n",
    "\n",
    "$$\\mathrm{FFN}(x)=\\max(0, xW_1 + b_1) W_2 + b_2$$\n",
    "\n",
    "虽然不同位置的线性变换是相同的,但它们在不同层之间使用不同的参数。\n",
    "另一种描述方式是将其视为核大小为1的两个卷积。输入和输出的维度是\n",
    "$d_{\\text{model}}=512$,内层的维度是$d_{ff}=2048$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2a9fa",
   "metadata": {
    "id": "6HHCemCxTsqH"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a5443",
   "metadata": {
    "id": "dR1YM520TsqH"
   },
   "source": [
    "## 嵌入和Softmax\n",
    "\n",
    "与其他序列转导模型类似，我们使用学习得到的嵌入将输入标记和输出标记转换为维度为$d_{\\text{model}}$的向量。\n",
    "我们还使用常规的学习得到的线性变换和softmax函数将解码器输出转换为预测下一个标记的概率。\n",
    "在我们的模型中，两个嵌入层和softmax前的线性变换共享相同的权重矩阵，这类似于\n",
    "[(引用)](https://arxiv.org/abs/1608.05859)。在嵌入层中，我们将这些权重乘以$\\sqrt{d_{\\text{model}}}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e85a3e",
   "metadata": {
    "id": "pyrChq9qTsqH"
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae9ded",
   "metadata": {
    "id": "vOkdui-cTsqH"
   },
   "source": [
    "## 位置编码\n",
    "\n",
    "由于我们的模型不包含循环和卷积结构，为了让模型能够利用序列的顺序信息，我们必须\n",
    "在序列中注入一些关于标记相对或绝对位置的信息。为此，我们在编码器和解码器堆栈的底部\n",
    "为输入嵌入添加\"位置编码\"。位置编码具有与嵌入相同的维度$d_{\\text{model}}$，\n",
    "因此两者可以相加。位置编码有多种选择，包括可学习的和固定的\n",
    "[(引用)](https://arxiv.org/pdf/1705.03122.pdf)。\n",
    "\n",
    "在本工作中，我们使用不同频率的正弦和余弦函数：\n",
    "\n",
    "$$PE_{(pos,2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})$$\n",
    "\n",
    "$$PE_{(pos,2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})$$\n",
    "\n",
    "其中$pos$是位置，$i$是维度。也就是说，位置编码的每个维度对应一个正弦曲线。\n",
    "波长构成了从$2\\pi$到$10000 \\cdot 2\\pi$的几何级数。我们选择这个函数是因为\n",
    "我们假设它能让模型轻松学习关注相对位置，因为对于任何固定偏移量$k$，$PE_{pos+k}$\n",
    "都可以表示为$PE_{pos}$的线性函数。\n",
    "\n",
    "此外，我们对编码器和解码器堆栈中的嵌入和位置编码的和应用dropout。\n",
    "对于基础模型，我们使用$P_{drop}=0.1$的比率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8b25e",
   "metadata": {
    "id": "zaHGD4yJTsqH"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8fe2e",
   "metadata": {
    "id": "EfHacTJLTsqH"
   },
   "source": [
    "\n",
    "> 下面的位置编码将基于位置添加正弦波。波的频率和偏移在每个维度上都不相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fe43d",
   "metadata": {
    "id": "rnvHk_1QokC6",
    "type": "example"
   },
   "outputs": [],
   "source": [
    "def example_positional():\n",
    "    pe = PositionalEncoding(20, 0)\n",
    "    y = pe.forward(torch.zeros(1, 100, 20))\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"embedding\": y[0, :, dim],\n",
    "                    \"dimension\": dim,\n",
    "                    \"position\": list(range(100)),\n",
    "                }\n",
    "            )\n",
    "            for dim in [4, 5, 6, 7]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=800)\n",
    "        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_positional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3084e",
   "metadata": {
    "id": "g8rZNCrzTsqI"
   },
   "source": [
    "\n",
    "我们还尝试使用学习得到的位置嵌入[(引用)](https://arxiv.org/pdf/1705.03122.pdf)，\n",
    "发现两种版本产生了几乎相同的结果。我们选择正弦版本是因为它可能允许模型推广到比训练\n",
    "期间遇到的序列更长的序列长度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddcf618",
   "metadata": {
    "id": "iwNKCzlyTsqI"
   },
   "source": [
    "## 完整模型\n",
    "\n",
    "> 这里我们定义一个从超参数到完整模型的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9a24d",
   "metadata": {
    "id": "mPe1ES0UTsqI"
   },
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0fcf1",
   "metadata": {},
   "source": [
    "## 推理:\n",
    "\n",
    "> 这里我们进行一个前向步骤来生成模型的预测。我们尝试使用我们的transformer来记忆输入。\n",
    "由于模型还未经过训练，你会看到输出是随机生成的。在下一个教程中，我们将构建训练函数，\n",
    "并尝试训练我们的模型来记忆1到10的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test():\n",
    "    test_model = make_model(11, 11, 2)\n",
    "    test_model.eval()\n",
    "    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "    src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "    memory = test_model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).type_as(src)\n",
    "\n",
    "    for i in range(9):\n",
    "        out = test_model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = test_model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "\n",
    "    print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    for _ in range(10):\n",
    "        inference_test()\n",
    "\n",
    "\n",
    "show_example(run_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bd52a",
   "metadata": {},
   "source": [
    "# 第二部分：模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec9850",
   "metadata": {
    "id": "05s6oT9fTsqI"
   },
   "source": [
    "# 训练\n",
    "\n",
    "本节描述我们模型的训练方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00017f0",
   "metadata": {
    "id": "fTxlofs4TsqI"
   },
   "source": [
    "\n",
    "> 我们暂停一下,介绍一些训练标准编码器-解码器模型所需的工具。\n",
    "> 首先我们定义一个batch对象,用于在训练时保存源序列和目标序列,\n",
    "> 同时构建相应的掩码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc3a04",
   "metadata": {
    "id": "G7SkCenXTsqI"
   },
   "source": [
    "## 批处理和掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
    "\n",
    "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:, :-1]\n",
    "            self.tgt_y = tgt[:, 1:]\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f515400",
   "metadata": {
    "id": "cKkw5GjLTsqI"
   },
   "source": [
    "\n",
    "> 接下来我们创建一个通用的训练和评分函数来跟踪损失。我们传入一个通用的损失计算函数,\n",
    "> 该函数同时也处理参数更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805a13f",
   "metadata": {
    "id": "Q8zzeUc0TsqJ"
   },
   "source": [
    "## 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "\n",
    "    step: int = 0  # Steps in the current epoch\n",
    "    accum_step: int = 0  # Number of gradient accumulation steps\n",
    "    samples: int = 0  # total # of examples used\n",
    "    tokens: int = 0  # total # of tokens processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1bdbb",
   "metadata": {
    "id": "2HAZD3hiTsqJ"
   },
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    data_iter,\n",
    "    model,\n",
    "    loss_compute,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mode=\"train\",\n",
    "    accum_iter=1,\n",
    "    train_state=TrainState(),\n",
    "):\n",
    "    \"\"\"Train a single epoch\"\"\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    n_accum = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(\n",
    "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
    "        )\n",
    "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
    "        # loss_node = loss_node / accum_iter\n",
    "        if mode == \"train\" or mode == \"train+log\":\n",
    "            loss_node.backward()\n",
    "            train_state.step += 1\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            train_state.tokens += batch.ntokens\n",
    "            if i % accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                n_accum += 1\n",
    "                train_state.accum_step += 1\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                (\n",
    "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
    "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
    "                )\n",
    "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
    "            )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6dbff0",
   "metadata": {
    "id": "aB1IF0foTsqJ"
   },
   "source": [
    "## 训练数据和批处理\n",
    "\n",
    "我们在标准的WMT 2014英德数据集上进行训练,该数据集包含约450万个句子对。\n",
    "使用字节对编码(byte-pair encoding)对句子进行编码,共享的源语言-目标语言词表大小约为37000个词元。\n",
    "对于英法翻译,我们使用了明显更大的WMT 2014英法数据集,其包含3600万个句子,\n",
    "并将词元分割成32000个词片(word-piece)词表。\n",
    "\n",
    "根据序列的近似长度将句子对组合成批次。每个训练批次包含一组句子对,\n",
    "大约包含25000个源语言词元和25000个目标语言词元。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cefb06",
   "metadata": {
    "id": "F1mTQatiTsqJ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 硬件和训练计划\n",
    "\n",
    "我们在一台配备8个NVIDIA P100 GPU的机器上训练模型。对于使用论文中描述的超参数的基础模型,\n",
    "每个训练步骤大约需要0.4秒。我们训练基础模型共100,000步,总计12小时。对于我们的大型模型,\n",
    "每步训练时间为1.0秒。大型模型训练了300,000步(3.5天)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8b70b",
   "metadata": {
    "id": "-utZeuGcTsqJ"
   },
   "source": [
    "## 优化器\n",
    "\n",
    "我们使用Adam优化器[(引用)](https://arxiv.org/abs/1412.6980),\n",
    "参数设置为$\\beta_1=0.9$、$\\beta_2=0.98$和$\\epsilon=10^{-9}$。\n",
    "在训练过程中,我们根据以下公式调整学习率:\n",
    "\n",
    "$$\n",
    "lrate = d_{\\text{model}}^{-0.5} \\cdot\n",
    "  \\min({step\\_num}^{-0.5},\n",
    "    {step\\_num} \\cdot {warmup\\_steps}^{-1.5})\n",
    "$$\n",
    "\n",
    "这相当于在前$warmup\\_steps$个训练步骤中线性增加学习率,之后按步数的平方根的倒数\n",
    "比例减小学习率。我们使用$warmup\\_steps=4000$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522d892",
   "metadata": {
    "id": "39FbYnt-TsqJ"
   },
   "source": [
    "\n",
    "> 注意:这部分非常重要。需要使用这种设置来训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c771e",
   "metadata": {
    "id": "hlbojFkjTsqJ"
   },
   "source": [
    "\n",
    "> 这个模型在不同模型大小和优化超参数下的学习曲线示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf0233",
   "metadata": {
    "id": "zUz3PdAnVg4o"
   },
   "outputs": [],
   "source": [
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b972d2",
   "metadata": {
    "id": "l1bnrlnSV8J5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example_learning_schedule():\n",
    "    opts = [\n",
    "        [512, 1, 4000],  # example 1\n",
    "        [512, 1, 8000],  # example 2\n",
    "        [256, 1, 4000],  # example 3\n",
    "    ]\n",
    "\n",
    "    dummy_model = torch.nn.Linear(1, 1)\n",
    "    learning_rates = []\n",
    "\n",
    "    # we have 3 examples in opts list.\n",
    "    for idx, example in enumerate(opts):\n",
    "        # run 20000 epoch for each example\n",
    "        optimizer = torch.optim.Adam(\n",
    "            dummy_model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9\n",
    "        )\n",
    "        lr_scheduler = LambdaLR(\n",
    "            optimizer=optimizer, lr_lambda=lambda step: rate(step, *example)\n",
    "        )\n",
    "        tmp = []\n",
    "        # take 20K dummy training steps, save the learning rate at each step\n",
    "        for step in range(20000):\n",
    "            tmp.append(optimizer.param_groups[0][\"lr\"])\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        learning_rates.append(tmp)\n",
    "\n",
    "    learning_rates = torch.tensor(learning_rates)\n",
    "\n",
    "    # Enable altair to handle more than 5000 rows\n",
    "    alt.data_transformers.disable_max_rows()\n",
    "\n",
    "    opts_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Learning Rate\": learning_rates[warmup_idx, :],\n",
    "                    \"model_size:warmup\": [\"512:4000\", \"512:8000\", \"256:4000\"][\n",
    "                        warmup_idx\n",
    "                    ],\n",
    "                    \"step\": range(20000),\n",
    "                }\n",
    "            )\n",
    "            for warmup_idx in [0, 1, 2]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(opts_data)\n",
    "        .mark_line()\n",
    "        .properties(width=600)\n",
    "        .encode(x=\"step\", y=\"Learning Rate\", color=\"model_size:warmup:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "example_learning_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ae3dd",
   "metadata": {
    "id": "7T1uD15VTsqK"
   },
   "source": [
    "## 正则化\n",
    "\n",
    "### 标签平滑\n",
    "\n",
    "在训练过程中，我们使用了值为$\\epsilon_{ls}=0.1$的标签平滑技术\n",
    "[(引用)](https://arxiv.org/abs/1512.00567)。\n",
    "这会降低困惑度，因为模型学会了更加不确定，但是\n",
    "提高了准确率和BLEU分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c9d29",
   "metadata": {
    "id": "kNoAVD8bTsqK"
   },
   "source": [
    "\n",
    "> 我们使用KL散度损失来实现标签平滑。我们不使用\n",
    "> one-hot目标分布，而是创建一个分布，使其对正确词有\n",
    "> `confidence`的置信度，剩余的`smoothing`质量\n",
    "> 分布在整个词表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161294f",
   "metadata": {
    "id": "shU2GyiETsqK",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, true_dist.clone().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa54ee",
   "metadata": {
    "id": "jCxUrlUyTsqK"
   },
   "source": [
    "\n",
    "> 这里我们可以看到基于置信度的词语概率质量分布的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3153f",
   "metadata": {
    "id": "EZtKaaQNTsqK",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Example of label smoothing.\n",
    "\n",
    "\n",
    "def example_label_smoothing():\n",
    "    crit = LabelSmoothing(5, 0, 0.4)\n",
    "    predict = torch.FloatTensor(\n",
    "        [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "        ]\n",
    "    )\n",
    "    crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"target distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"columns\": y,\n",
    "                    \"rows\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(5)\n",
    "            for x in range(5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect(color=\"Blue\", opacity=1)\n",
    "        .properties(height=200, width=200)\n",
    "        .encode(\n",
    "            alt.X(\"columns:O\", title=None),\n",
    "            alt.Y(\"rows:O\", title=None),\n",
    "            alt.Color(\n",
    "                \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n",
    "            ),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_label_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda47038",
   "metadata": {
    "id": "CGM8J1veTsqK"
   },
   "source": [
    "\n",
    "> 标签平滑实际上会在模型对某个选择变得过于自信时开始惩罚模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405e054",
   "metadata": {
    "id": "78EHzLP7TsqK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loss(x, crit):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n",
    "    return crit(predict.log(), torch.LongTensor([1])).data\n",
    "\n",
    "\n",
    "def penalization_visualization():\n",
    "    crit = LabelSmoothing(5, 0, 0.1)\n",
    "    loss_data = pd.DataFrame(\n",
    "        {\n",
    "            \"Loss\": [loss(x, crit) for x in range(1, 100)],\n",
    "            \"Steps\": list(range(99)),\n",
    "        }\n",
    "    ).astype(\"float\")\n",
    "\n",
    "    return (\n",
    "        alt.Chart(loss_data)\n",
    "        .mark_line()\n",
    "        .properties(width=350)\n",
    "        .encode(\n",
    "            x=\"Steps\",\n",
    "            y=\"Loss\",\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(penalization_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77bdfb",
   "metadata": {
    "id": "67lUqeLXTsqK"
   },
   "source": [
    "# 第一个示例\n",
    "\n",
    "> 我们可以从尝试一个简单的复制任务开始。给定一个来自小型词汇表的随机输入符号集，\n",
    "> 目标是生成回相同的符号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e1b36",
   "metadata": {
    "id": "jJa-89_pTsqK"
   },
   "source": [
    "## 合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415ad3c",
   "metadata": {
    "id": "g1aTxeqqTsqK"
   },
   "outputs": [],
   "source": [
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.randint(1, V, size=(batch_size, 10))\n",
    "        data[:, 0] = 1\n",
    "        src = data.requires_grad_(False).clone().detach()\n",
    "        tgt = data.requires_grad_(False).clone().detach()\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a193cc8",
   "metadata": {
    "id": "XTXwD9hUTsqK"
   },
   "source": [
    "## 损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb377bf",
   "metadata": {
    "id": "3J8EJm87TsqK"
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "\n",
    "    def __init__(self, generator, criterion):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        sloss = (\n",
    "            self.criterion(\n",
    "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "            )\n",
    "            / norm\n",
    "        )\n",
    "        return sloss.data * norm, sloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195f67d",
   "metadata": {
    "id": "eDAI7ELUTsqL"
   },
   "source": [
    "## 贪婪解码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478feeb6",
   "metadata": {
    "id": "LFkWakplTsqL",
    "lines_to_next_cell": 0,
    "tags": []
   },
   "source": [
    "> 为了简单起见,这段代码使用贪婪解码来预测翻译结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6717b",
   "metadata": {
    "id": "N2UOpnT3bIyU",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddd8c0",
   "metadata": {
    "id": "qgIZ2yEtdYwe",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the simple copy task.\n",
    "\n",
    "\n",
    "def example_simple_model():\n",
    "    V = 11\n",
    "    criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "    model = make_model(V, V, N=2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, model_size=model.src_embed[0].d_model, factor=1.0, warmup=400\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    batch_size = 80\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        run_epoch(\n",
    "            data_gen(V, batch_size, 20),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train\",\n",
    "        )\n",
    "        model.eval()\n",
    "        run_epoch(\n",
    "            data_gen(V, batch_size, 5),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )[0]\n",
    "\n",
    "    model.eval()\n",
    "    src = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "    max_len = src.shape[1]\n",
    "    src_mask = torch.ones(1, 1, max_len)\n",
    "    print(greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0))\n",
    "\n",
    "\n",
    "# execute_example(example_simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484d618",
   "metadata": {
    "id": "OpuQv2GsTsqL"
   },
   "source": [
    "# 第三部分：真实世界示例\n",
    "\n",
    "> 现在我们来看一个使用Multi30k德英翻译任务的真实世界示例。\n",
    "> 这个任务比论文中考虑的WMT任务小得多，但它展示了整个\n",
    "> 系统的工作原理。我们还将展示如何使用多GPU处理来\n",
    "> 显著提升运行速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58071da",
   "metadata": {
    "id": "8y9dpfolTsqL",
    "tags": []
   },
   "source": [
    "## 数据加载\n",
    "\n",
    "> 我们将使用torchtext和spacy进行数据集加载和\n",
    "> 分词处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa77680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载spacy分词器模型，如果尚未下载则进行下载\n",
    "\n",
    "\n",
    "def load_tokenizers():\n",
    "\n",
    "    try:\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download de_core_news_sm\")\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_de, spacy_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b6838",
   "metadata": {
    "id": "t4BszXXJTsqL",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer):\n",
    "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer, index):\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer(from_to_tuple[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0830dcf",
   "metadata": {
    "id": "jU3kVlV5okC-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_vocabulary(spacy_de, spacy_en):\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    print(\"Building German Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_de, index=0),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    print(\"Building English Vocabulary ...\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        yield_tokens(train + val + test, tokenize_en, index=1),\n",
    "        min_freq=2,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
    "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
    "\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "def load_vocab(spacy_de, spacy_en):\n",
    "    if not exists(\"vocab.pt\"):\n",
    "        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)\n",
    "        torch.save((vocab_src, vocab_tgt), \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_src, vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(len(vocab_src))\n",
    "    print(len(vocab_tgt))\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "if is_interactive_notebook():\n",
    "    # global variables used later in the script\n",
    "    spacy_de, spacy_en = show_example(load_tokenizers)\n",
    "    vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_de, spacy_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3f220",
   "metadata": {
    "id": "-l-TFwzfTsqL"
   },
   "source": [
    "\n",
    "> 批处理对速度有很大影响。我们希望批次划分得非常均匀，\n",
    "> 同时将填充降到最低。为此，我们需要对默认的torchtext批处理\n",
    "> 进行一些修改。这段代码对默认的批处理进行了修补，以确保我们\n",
    "> 能搜索足够多的句子来找到紧凑的批次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b651b61",
   "metadata": {
    "id": "kDEj-hCgokC-",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1580c2e",
   "metadata": {
    "id": "wGsIHFgOokC_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(\n",
    "    batch,\n",
    "    src_pipeline,\n",
    "    tgt_pipeline,\n",
    "    src_vocab,\n",
    "    tgt_vocab,\n",
    "    device,\n",
    "    max_padding=128,\n",
    "    pad_id=2,\n",
    "):\n",
    "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
    "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
    "    src_list, tgt_list = [], []\n",
    "    for (_src, _tgt) in batch:\n",
    "        processed_src = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    src_vocab(src_pipeline(_src)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        processed_tgt = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    max_padding - len(processed_src),\n",
    "                ),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "        tgt_list.append(\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (0, max_padding - len(processed_tgt)),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    src = torch.stack(src_list)\n",
    "    tgt = torch.stack(tgt_list)\n",
    "    return (src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce0b70",
   "metadata": {
    "id": "ka2Ce_WIokC_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    device,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_de,\n",
    "    spacy_en,\n",
    "    batch_size=12000,\n",
    "    max_padding=128,\n",
    "    is_distributed=True,\n",
    "):\n",
    "    # def create_dataloaders(batch_size=12000):\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return collate_batch(\n",
    "            batch,\n",
    "            tokenize_de,\n",
    "            tokenize_en,\n",
    "            vocab_src,\n",
    "            vocab_tgt,\n",
    "            device,\n",
    "            max_padding=max_padding,\n",
    "            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n",
    "        )\n",
    "\n",
    "    train_iter, valid_iter, test_iter = datasets.Multi30k(\n",
    "        language_pair=(\"de\", \"en\")\n",
    "    )\n",
    "\n",
    "    train_iter_map = to_map_style_dataset(\n",
    "        train_iter\n",
    "    )  # DistributedSampler needs a dataset len()\n",
    "    train_sampler = (\n",
    "        DistributedSampler(train_iter_map) if is_distributed else None\n",
    "    )\n",
    "    valid_iter_map = to_map_style_dataset(valid_iter)\n",
    "    valid_sampler = (\n",
    "        DistributedSampler(valid_iter_map) if is_distributed else None\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(valid_sampler is None),\n",
    "        sampler=valid_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19826a1",
   "metadata": {
    "id": "90qM8RzCTsqM"
   },
   "source": [
    "## Training the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895121d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_worker(\n",
    "    gpu,\n",
    "    ngpus_per_node,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_de,\n",
    "    spacy_en,\n",
    "    config,\n",
    "    is_distributed=False,\n",
    "):\n",
    "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    pad_idx = vocab_tgt[\"<blank>\"]\n",
    "    d_model = 512\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.cuda(gpu)\n",
    "    module = model\n",
    "    is_main_process = True\n",
    "    if is_distributed:\n",
    "        dist.init_process_group(\n",
    "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
    "        )\n",
    "        model = DDP(model, device_ids=[gpu])\n",
    "        module = model.module\n",
    "        is_main_process = gpu == 0\n",
    "\n",
    "    criterion = LabelSmoothing(\n",
    "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
    "    )\n",
    "    criterion.cuda(gpu)\n",
    "\n",
    "    train_dataloader, valid_dataloader = create_dataloaders(\n",
    "        gpu,\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
    "        max_padding=config[\"max_padding\"],\n",
    "        is_distributed=is_distributed,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
    "        ),\n",
    "    )\n",
    "    train_state = TrainState()\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        if is_distributed:\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "            valid_dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        model.train()\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
    "        _, train_state = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train+log\",\n",
    "            accum_iter=config[\"accum_iter\"],\n",
    "            train_state=train_state,\n",
    "        )\n",
    "\n",
    "        GPUtil.showUtilization()\n",
    "        if is_main_process:\n",
    "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
    "            torch.save(module.state_dict(), file_path)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
    "        model.eval()\n",
    "        sloss = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )\n",
    "        print(sloss)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if is_main_process:\n",
    "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
    "        torch.save(module.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc2561",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    from the_annotated_transformer import train_worker\n",
    "\n",
    "    ngpus = torch.cuda.device_count()\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
    "    print(f\"Number of GPUs detected: {ngpus}\")\n",
    "    print(\"Spawning training processes ...\")\n",
    "    mp.spawn(\n",
    "        train_worker,\n",
    "        nprocs=ngpus,\n",
    "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    if config[\"distributed\"]:\n",
    "        train_distributed_model(\n",
    "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
    "        )\n",
    "    else:\n",
    "        train_worker(\n",
    "            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n",
    "        )\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    config = {\n",
    "        \"batch_size\": 32,\n",
    "        \"distributed\": False,\n",
    "        \"num_epochs\": 8,\n",
    "        \"accum_iter\": 10,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 72,\n",
    "        \"warmup\": 3000,\n",
    "        \"file_prefix\": \"multi30k_model_\",\n",
    "    }\n",
    "    model_path = \"multi30k_model_final.pt\"\n",
    "    if not exists(model_path):\n",
    "        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "if is_interactive_notebook():\n",
    "    model = load_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c39f76",
   "metadata": {
    "id": "RZK_VjDPTsqN"
   },
   "source": [
    "\n",
    "> 训练完成后,我们可以对模型进行解码以生成一组翻译结果。这里我们仅翻译验证集中的第一个句子。\n",
    "> 由于这个数据集比较小,使用贪婪搜索的翻译结果也相当准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe95a62",
   "metadata": {
    "id": "L50i0iEXTsqN"
   },
   "source": [
    "# 附加组件：BPE、搜索、平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5111f76",
   "metadata": {
    "id": "NBx1C2_NTsqN"
   },
   "source": [
    "\n",
    "> 到目前为止,我们主要介绍了Transformer模型本身。还有四个方面我们没有明确涉及。\n",
    "> 这些额外的功能都已在[OpenNMT-py](https://github.com/opennmt/opennmt-py)中实现。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ed9d8",
   "metadata": {
    "id": "UpqV1mWnTsqN"
   },
   "source": [
    "\n",
    "> 1) BPE/词片(Word-piece)：我们可以使用库来首先将数据预处理成子词单元。\n",
    "> 参见Rico Sennrich的[subword-nmt](https://github.com/rsennrich/subword-nmt)\n",
    "> 实现。这些模型会将训练数据转换成如下形式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a19566",
   "metadata": {
    "id": "hwJ_9J0BTsqN"
   },
   "source": [
    "▁Die ▁Protokoll datei ▁kann ▁ heimlich ▁per ▁E - Mail ▁oder ▁FTP\n",
    "▁an ▁einen ▁bestimmte n ▁Empfänger ▁gesendet ▁werden ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e5191",
   "metadata": {
    "id": "9HwejYkpTsqN"
   },
   "source": [
    "\n",
    "> 2) 共享嵌入：当使用共享词表的BPE时,我们可以在源语言/目标语言/生成器之间共享相同的权重向量。\n",
    "> 详见[(引用)](https://arxiv.org/abs/1608.05859)。要将此功能添加到模型中,只需执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd3be5",
   "metadata": {
    "id": "tb3j3CYLTsqN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model.src_embed[0].lut.weight = model.tgt_embeddings[0].lut.weight\n",
    "    model.generator.lut.weight = model.tgt_embed[0].lut.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b10d2",
   "metadata": {
    "id": "xDKJsSwRTsqN"
   },
   "source": [
    "\n",
    "> 3) 集束搜索(Beam Search)：这里过于复杂,不做详细介绍。可以参考\n",
    "> [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py/)\n",
    "> 中的PyTorch实现。\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a71c06",
   "metadata": {
    "id": "wf3vVYGZTsqN"
   },
   "source": [
    "\n",
    "> 4) 模型平均：论文通过对最后k个检查点取平均来创建集成效果。如果我们\n",
    "> 有多个模型,可以在训练后执行这个操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ab34e",
   "metadata": {
    "id": "hAFEa78JokDB",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def average(model, models):\n",
    "    \"Average models into model\"\n",
    "    for ps in zip(*[m.params() for m in [model] + models]):\n",
    "        ps[0].copy_(torch.sum(*ps[1:]) / len(ps[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb0794",
   "metadata": {
    "id": "Kz5BYJ9sTsqO"
   },
   "source": [
    "# 结果\n",
    "\n",
    "在WMT 2014英德翻译任务中,大型Transformer模型(表2中的Transformer (big))\n",
    "的表现超过了此前报告的最佳模型(包括集成模型)2.0以上的BLEU分数,\n",
    "创造了28.4的新的SOTA(state-of-the-art) BLEU分数。该模型的配置列在表3的\n",
    "最后一行。训练在8个P100 GPU上花费了3.5天。即使是我们的基础模型也超过了\n",
    "所有已发表的模型和集成模型,而且训练成本只是其他竞争模型的一小部分。\n",
    "\n",
    "在WMT 2014英法翻译任务中,我们的大型模型达到了41.0的BLEU分数,超过了\n",
    "所有此前发表的单模型,训练成本不到之前最先进模型的1/4。用于英法翻译的\n",
    "Transformer (big)模型使用了dropout率Pdrop = 0.1,而不是0.3。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d71a3",
   "metadata": {},
   "source": [
    "![](images/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4c161",
   "metadata": {
    "id": "cPcnsHvQTsqO"
   },
   "source": [
    "\n",
    "\n",
    "> 使用上一节中的额外扩展,OpenNMT-py的复现在EN-DE WMT上达到了26.9。\n",
    "> 这里我已经将这些参数加载到我们的重新实现中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e27754",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load data and model for output checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e4046",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def check_outputs(\n",
    "    valid_dataloader,\n",
    "    model,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    n_examples=15,\n",
    "    pad_idx=2,\n",
    "    eos_string=\"</s>\",\n",
    "):\n",
    "    results = [()] * n_examples\n",
    "    for idx in range(n_examples):\n",
    "        print(\"\\nExample %d ========\\n\" % idx)\n",
    "        b = next(iter(valid_dataloader))\n",
    "        rb = Batch(b[0], b[1], pad_idx)\n",
    "        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n",
    "\n",
    "        src_tokens = [\n",
    "            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n",
    "        ]\n",
    "        tgt_tokens = [\n",
    "            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            \"Source Text (Input)        : \"\n",
    "            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        print(\n",
    "            \"Target Text (Ground Truth) : \"\n",
    "            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n",
    "        )\n",
    "        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n",
    "        model_txt = (\n",
    "            \" \".join(\n",
    "                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n",
    "            ).split(eos_string, 1)[0]\n",
    "            + eos_string\n",
    "        )\n",
    "        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n",
    "        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_model_example(n_examples=5):\n",
    "    global vocab_src, vocab_tgt, spacy_de, spacy_en\n",
    "\n",
    "    print(\"Preparing Data ...\")\n",
    "    _, valid_dataloader = create_dataloaders(\n",
    "        torch.device(\"cpu\"),\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=1,\n",
    "        is_distributed=False,\n",
    "    )\n",
    "\n",
    "    print(\"Loading Trained Model ...\")\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n",
    "    )\n",
    "\n",
    "    print(\"Checking Model Outputs:\")\n",
    "    example_data = check_outputs(\n",
    "        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n",
    "    )\n",
    "    return model, example_data\n",
    "\n",
    "\n",
    "# execute_example(run_model_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630613e3",
   "metadata": {
    "id": "0ZkkNTKLTsqO"
   },
   "source": [
    "## 注意力可视化\n",
    "\n",
    "> 即使使用贪婪解码器，翻译的效果看起来也相当不错。我们\n",
    "> 可以进一步将其可视化，以观察注意力机制在每一层中发生了什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n",
    "    \"convert a dense matrix to a data frame with row and column indices\"\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r, c]),\n",
    "                \"%.3d %s\"\n",
    "                % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n",
    "                \"%.3d %s\"\n",
    "                % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        # if float(m[r,c]) != 0 and r < max_row and c < max_col],\n",
    "        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def attn_map(attn, layer, head, row_tokens, col_tokens, max_dim=30):\n",
    "    df = mtx2df(\n",
    "        attn[0, head].data,\n",
    "        max_dim,\n",
    "        max_dim,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\", axis=alt.Axis(title=\"\")),\n",
    "            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"\")),\n",
    "            color=\"value\",\n",
    "            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        .properties(height=400, width=400)\n",
    "        .interactive()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788023c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encoder(model, layer):\n",
    "    return model.encoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_self(model, layer):\n",
    "    return model.decoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_src(model, layer):\n",
    "    return model.decoder.layers[layer].src_attn.attn\n",
    "\n",
    "\n",
    "def visualize_layer(model, layer, getter_fn, ntokens, row_tokens, col_tokens):\n",
    "    # ntokens = last_example[0].ntokens\n",
    "    attn = getter_fn(model, layer)\n",
    "    n_heads = attn.shape[1]\n",
    "    charts = [\n",
    "        attn_map(\n",
    "            attn,\n",
    "            0,\n",
    "            h,\n",
    "            row_tokens=row_tokens,\n",
    "            col_tokens=col_tokens,\n",
    "            max_dim=ntokens,\n",
    "        )\n",
    "        for h in range(n_heads)\n",
    "    ]\n",
    "    assert n_heads == 8\n",
    "    return alt.vconcat(\n",
    "        charts[0]\n",
    "        # | charts[1]\n",
    "        | charts[2]\n",
    "        # | charts[3]\n",
    "        | charts[4]\n",
    "        # | charts[5]\n",
    "        | charts[6]\n",
    "        # | charts[7]\n",
    "        # layer + 1 due to 0-indexing\n",
    "    ).properties(title=\"Layer %d\" % (layer + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3814aa6",
   "metadata": {},
   "source": [
    "## Encoder Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f40dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_encoder_self():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[\n",
    "        len(example_data) - 1\n",
    "    ]  # batch object for the final example\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model, layer, get_encoder, len(example[1]), example[1], example[1]\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        # & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        # & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        # & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_encoder_self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddb59b",
   "metadata": {},
   "source": [
    "## Decoder Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfc3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_decoder_self():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[len(example_data) - 1]\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model,\n",
    "            layer,\n",
    "            get_decoder_self,\n",
    "            len(example[1]),\n",
    "            example[1],\n",
    "            example[1],\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_decoder_self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce786c1",
   "metadata": {},
   "source": [
    "## Decoder Src Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6b8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_decoder_src():\n",
    "    model, example_data = run_model_example(n_examples=1)\n",
    "    example = example_data[len(example_data) - 1]\n",
    "\n",
    "    layer_viz = [\n",
    "        visualize_layer(\n",
    "            model,\n",
    "            layer,\n",
    "            get_decoder_src,\n",
    "            max(len(example[1]), len(example[2])),\n",
    "            example[1],\n",
    "            example[2],\n",
    "        )\n",
    "        for layer in range(6)\n",
    "    ]\n",
    "    return alt.hconcat(\n",
    "        layer_viz[0]\n",
    "        & layer_viz[1]\n",
    "        & layer_viz[2]\n",
    "        & layer_viz[3]\n",
    "        & layer_viz[4]\n",
    "        & layer_viz[5]\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(viz_decoder_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce885463",
   "metadata": {
    "id": "nSseuCcATsqO"
   },
   "source": [
    "# 结论\n",
    "\n",
    "希望这份代码能对未来的研究工作有所帮助。如果您遇到任何问题，\n",
    "请随时与我们联系。\n",
    "\n",
    "\n",
    "此致，\n",
    "Sasha Rush、Austin Huang、Suraj Subramanian、Jonathan Sum、Khalid Almubarak、\n",
    "Stella Biderman"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
